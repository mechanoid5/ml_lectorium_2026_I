{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EDA**\n",
    "\n",
    "Евгений Борисов esborisov@sevsu.ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* проверка на пропуски\n",
    "* проверка на дубликаты\n",
    "* проверка на противоречивую разметку\n",
    "* статистические характеристики: корреляции, распределения, персентили\n",
    "* поиск аномалий\n",
    "* визуализация, признаки попарно, PCA, статистики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "pd.options.display.float_format = '{:,.3f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.3 ms, sys: 9.75 ms, total: 59.1 ms\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "data = fetch_ucirepo(id=186) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# изучаем структуру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'metadata', 'variables']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( list(data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uci_id',\n",
       " 'name',\n",
       " 'repository_url',\n",
       " 'data_url',\n",
       " 'abstract',\n",
       " 'area',\n",
       " 'tasks',\n",
       " 'characteristics',\n",
       " 'num_instances',\n",
       " 'num_features',\n",
       " 'feature_types',\n",
       " 'demographics',\n",
       " 'target_col',\n",
       " 'index_col',\n",
       " 'has_missing_values',\n",
       " 'missing_values_symbol',\n",
       " 'year_of_dataset_creation',\n",
       " 'last_updated',\n",
       " 'dataset_doi',\n",
       " 'creators',\n",
       " 'intro_paper',\n",
       " 'additional_info']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( list(data['metadata']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data['metadata']['abstract'])\n",
    "# print(data['metadata']['tasks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/metadata-abstract.txt','wt') as f: f.write(data['metadata']['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display( data['variables'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['variables'].to_csv('data/variables.csv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = data['data']['original']\n",
    "# display(len(df))\n",
    "# display(df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('data/data.csv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data.csv',sep='\\t')\n",
    "display(len(df))\n",
    "display(df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['id'] = range(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# изучение и визуализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заменяем название на номер\n",
    "df['color_'] = pd.Categorical(df['color']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сквозная нумерация классов от нуля\n",
    "df['target'] = pd.Categorical(df['quality']).codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.sample(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# список признаков\n",
    "cols_features =[\n",
    "#    'id',\n",
    "    'fixed_acidity',\n",
    "    'volatile_acidity',\n",
    "    'citric_acid',\n",
    "    'residual_sugar',\n",
    "    'chlorides',\n",
    "    'free_sulfur_dioxide',\n",
    "    'total_sulfur_dioxide',\n",
    "    'density',\n",
    "    'pH',\n",
    "    'sulphates',\n",
    "    'alcohol',\n",
    "#    'color',\n",
    "    'color_',\n",
    "#    'target'\n",
    "#    'quality',    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## проверка на дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка на дубликаты\n",
    "display( len(df) )\n",
    "display( len( df[cols_features].drop_duplicates() ) )\n",
    "display( len( df[cols_features+['target']].drop_duplicates() ) )\n",
    "# ЕСТЬ ДУБЛИКАТЫ ЗАПИСЕЙ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем дубликаты\n",
    "display( len(df) )\n",
    "df = df.drop_duplicates(cols_features+['target']).reset_index(drop=True)\n",
    "display( len(df) )\n",
    "display( df.sample(3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## проверка на противоречивую разметку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка на противоречивую разметку\n",
    "# т.е. таблица НЕ должна содержать одинаковых но разноразмеченных примеров\n",
    "assert (df.groupby(cols_features)['target'].apply(set).reset_index()['target'].str.len()==1).all() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## сбалансированность датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = range(len(df))\n",
    "df.groupby('target')[['id']].count().T #.`plot.barh()\n",
    "# датасет не сбалансирован "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## распределения признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.pairplot(df[cols_features+['target']], hue='target',palette='viridis')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "# from matplotlib import colors as mcolors\n",
    "# colors = list(mcolors.CSS4_COLORS.keys()) \n",
    "# colors = np.random.permutation(colors)\n",
    "# colors = ['blue','green','red','cyan','magenta','yellow','black',]\n",
    "# colors = { n:c for n,c in enumerate(colors) }\n",
    "\n",
    "scatter_matrix(\n",
    "        df[cols_features], \n",
    "        figsize=(26, 26), \n",
    "        diagonal='hist', \n",
    "        alpha=.7, \n",
    "        s=5, \n",
    "        marker='o',\n",
    "        # color=df['target'].map(colors) \n",
    "        c=df['target'],\n",
    "        cmap='rainbow',    \n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.plot.kde?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# распределения признаков\n",
    "n_cols_plot = 3\n",
    "n_features = len(cols_features)\n",
    "n_rows_plot = int(np.ceil(len(cols_features)/n_cols_plot))\n",
    "\n",
    "fig = plt.figure( figsize=(4*n_cols_plot,3*n_rows_plot) )\n",
    "for n,f in enumerate(cols_features):\n",
    "    ax = plt.subplot(n_rows_plot,n_cols_plot,n+1) \n",
    "    # drop tiny class\n",
    "    df[df['target']!=6].groupby('target')[f].plot.kde(ax=ax)\n",
    "    ax.set_title(f)\n",
    "    ax.grid()\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center',ncol=n_features-1)  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # распределения признаков\n",
    "# n_cols_plot = 4\n",
    "# n_features = len(cols_features)\n",
    "# n_rows_plot = int(np.ceil(len(cols_features)/n_cols_plot))\n",
    "\n",
    "# df[cols_features].plot.box(subplots=True, layout=(n_rows_plot,n_cols_plot), figsize=(4*n_cols_plot,4*n_rows_plot), sharex=False,grid=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## корреляции признаков и таргета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lib.stat import CorrelationAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aca = CorrelationAnalyzer(df[cols_features+['target']])\n",
    "# ca.plot(abs_value=True,figsize=(9,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ca.hight(corr_bound=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ca.table[['target']].query('abs(target)>.2').sort_values('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# df_corr = df[cols_features[:5]].corr()\n",
    "# #display( df_corr.style.background_gradient(axis=None, vmin=-1, vmax=1, cmap='rainbow') )\n",
    "\n",
    "# mask = np.triu(np.ones_like(df_corr, dtype=bool))\n",
    "# plt.figure(figsize=(5,3))\n",
    "# sns.heatmap(\n",
    "#     df_corr, \n",
    "#     mask=mask, \n",
    "#     #center=0, \n",
    "#     annot=True, \n",
    "#     fmt='.2f', \n",
    "#     square=True, \n",
    "#     cmap='rainbow'\n",
    "# )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_corr = df[cols_features+['target']].corr()\n",
    "#display( df_corr.style.background_gradient(axis=None, vmin=-1, vmax=1, cmap='rainbow') )\n",
    "\n",
    "mask = np.triu(np.ones_like(df_corr, dtype=bool))\n",
    "plt.figure(figsize=(12,9))\n",
    "sns.heatmap(\n",
    "    df_corr.abs(), \n",
    "    mask=mask, \n",
    "    #center=0, \n",
    "    annot=True, \n",
    "    fmt='.2f', \n",
    "    square=True, \n",
    "    cmap='rainbow'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_lim = 0.4\n",
    "\n",
    "# fet_other = sorted(set(cols_features))\n",
    "# hi_corr = []\n",
    "# while len(fet_other) > 1:\n",
    "#     fet_name = fet_other[0]\n",
    "#     fet_other = fet_other[1:]\n",
    "#     df_corr_fet = df_corr.loc[fet_name,fet_other]\n",
    "#     hi_corr_ = [ [ fet_name, f, df_corr.loc[fet_name, f] ] for f in df_corr_fet[ df_corr_fet.abs()> corr_lim ].index ]\n",
    "#     if len(hi_corr_)>0: hi_corr.extend(hi_corr_)\n",
    "\n",
    "# # hi_corr    \n",
    "# pd.DataFrame(hi_corr ,columns=['fet0','fet1','corr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[cols_features+['target']].corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # корреляции признаков и таргета\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sb\n",
    "# fig, ax = plt.subplots(figsize=(10,10))\n",
    "# sb.heatmap( df[cols_features+['target']].corr(numeric_only=True), annot=True,ax=ax,cmap=\"rainbow\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # список признаков с высокой корреляцией с target\n",
    "# cols_features_ =[\n",
    "# #    'id',\n",
    "# #    'fixed_acidity',\n",
    "#     'volatile_acidity',\n",
    "# #    'citric_acid',\n",
    "# #    'residual_sugar',\n",
    "#     'chlorides',\n",
    "# #    'free_sulfur_dioxide',\n",
    "# #    'total_sulfur_dioxide',\n",
    "#     'density',\n",
    "# #    'pH',\n",
    "# #    'sulphates',\n",
    "#     'alcohol',\n",
    "# #    'color',\n",
    "#     'color_',\n",
    "# #    'target'\n",
    "# #    'quality',    \n",
    "# ]\n",
    "\n",
    "# # корреляции признаков и таргета\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sb\n",
    "# fig, ax = plt.subplots(figsize=(5,5))\n",
    "# sb.heatmap( df[cols_features_+['target']].corr(numeric_only=True), annot=True,ax=ax,cmap=\"rainbow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## поиск выбросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выявляем аномалии с помощью Isolation Forest   \n",
    "https://habr.com/ru/companies/otus/articles/881086/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Строим дерево, где каждый узел случайно выбирает один признак и случайное значение разбиения.\n",
    "* Рекурсивно делим данные, пока каждая точка не окажется в своём отдельном листе.\n",
    "* Считаем аномальность точки по тому, насколько быстро она была изолирована (чем короче путь, тем аномальнее)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# 5% данных считаем аномальными\n",
    "df['is_anomaly'] = IsolationForest(contamination=0.1).fit_predict(df[cols_features])==-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['target','is_anomaly'])[['id']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X2 = PCA(n_components=2).fit_transform(df[cols_features].values)\n",
    "display( X2.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "for c in [True,False]:\n",
    "    ax.scatter(X2[df['is_anomaly']==c, 0], X2[df['is_anomaly']==c, 1],s=1,label=f'{c}')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anom = df.query('is_anomaly').reset_index(drop=True)\n",
    "df = df.query('~is_anomaly').reset_index(drop=True)\n",
    "display( len(df),len(df_anom) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## слияние классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем центры классов как медианны\n",
    "# оцениваем близость медиан"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_median = df[cols_features+['target']].groupby('target').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "d = pairwise_distances(df_median, metric='euclidean')\n",
    "\n",
    "mask = np.triu(np.ones_like(d, dtype=bool))\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.heatmap(\n",
    "    d, \n",
    "    mask=mask, \n",
    "    #center=0, \n",
    "    annot=True, \n",
    "    fmt='.2f', \n",
    "    square=True, \n",
    "    cmap='rainbow'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.eye(*d.shape, dtype=bool)\n",
    "neighbor_idx = np.ma.masked_array(d, mask=mask).argmin(axis=0)\n",
    "d_ = d.flatten()[ np.ravel_multi_index((range(len(neighbor_idx)),neighbor_idx),d.shape) ]\n",
    "pd.DataFrame({\n",
    "    'class0':range(len(neighbor_idx)),\n",
    "    'class1':neighbor_idx,\n",
    "    'dist':d_\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "MeanShift(bandwidth=7.).fit(d).labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим классы 3,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3_6 = df.query('(target==6) or (target==3)').reset_index(drop=True)\n",
    "df = df.query('(target!=6) and (target!=3)').reset_index(drop=True)\n",
    "display( len(df),len(df_3_6) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединим классы 4,5 и 0,1\n",
    "df['target_'] = df['target'].apply(lambda t: 4 if t==5 else t).apply(lambda t: 1 if t==0 else t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('target_')[['id']].count().T #.`plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## отбор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Построение и отбор признаков. Часть 2: feature selection   \n",
    "https://proglib.io/p/postroenie-i-otbor-priznakov-chast-2-feature-selection-2021-09-25\n",
    "\n",
    "Методы отбора фич   \n",
    "https://habr.com/ru/articles/264915/\n",
    "\n",
    "Отбор признаков в задачах машинного обучения. Часть 1   \n",
    "https://habr.com/ru/articles/550978/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Количество пропущенных значений (удаляются признаки у которых процент пропущенных значений больше порогового).\n",
    "\n",
    "Коэффициент корреляции (удаляются признаки, у которых коэффициент корреляции больше порогового).\n",
    "\n",
    "Вариативность (удаляются признаки, состоящие из одного значения).\n",
    "\n",
    "Оценка важности признаков с помощью lightgbm \n",
    "(удаляются признаки, имеющие низкую важность в модели lightgbm. \n",
    "Следует применять только если lightgbm имеет хорошую точность.)\n",
    "\n",
    "\n",
    "VarianceThreshold отбирает признаки, у которых дисперсия меньше заданного значения. \n",
    "    \n",
    "SelectKBest и SelectPercentile оценивают взаимосвязь предикторов с целевой переменной используя статистические тесты, \n",
    "позволяя отобрать соответственно заданное количество и долю наилучших по заданному критерию признаков. \n",
    "В качестве статистических тестов используются F-тест, \n",
    "\n",
    "\n",
    "F-тест оценивает степень линейной зависимости между предикторами и целевой переменной, \n",
    "поэтому он лучше всего подойдёт для линейных моделей. \n",
    "Реализован в sklearn как f_regression и f_classif соответственно для регрессии и классификации.\n",
    "\n",
    "X2 тест используется в задах классификации и оценивает зависимость между признаками и классами целевой пременной. \n",
    "Стоит отметить, что этот тип тестов требует неотрицательных и правильно отмасштабированных признаков.\n",
    "\n",
    "mutual_info_regression / mutual_info_classif - взаимная информация показывает насколько чётко определена целевая переменная если известны значения предиктора. Этот тип тестов считается самым удобным в использовании - он хорошо работает \"из коробки\" и позволяет находить нелинейные зависимости. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df[cols_features_].values\n",
    "# X = df[cols_features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "importances = mutual_info_classif(df[cols_features].values, df['target_'].values)\n",
    "# importances = mutual_info_classif(df[cols_features].values, df['target'].values)\n",
    "importances = pd.Series(importances, cols_features).sort_values()\n",
    "importances.plot(kind='barh', color='teal',grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_features_ = list(importances.sort_values(ascending=False).head(5).index)\n",
    "cols_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.plotting import scatter_matrix\n",
    "# # from matplotlib import colors as mcolors\n",
    "# # colors = list(mcolors.CSS4_COLORS.keys()) \n",
    "# # colors = np.random.permutation(colors)\n",
    "# colors = ['blue','green','red','cyan','magenta','yellow','black',]\n",
    "# colors = { n:c for n,c in enumerate(colors) }\n",
    "\n",
    "# scatter_matrix(\n",
    "#         df[cols_features_], \n",
    "#         figsize=(7,7), \n",
    "#         diagonal='kde', \n",
    "#         alpha=.5, \n",
    "#         s=4, \n",
    "#         color=df['target'].map(colors) \n",
    "#     )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# sns.pairplot(df[cols_features_+['target']], hue='target',palette='rainbow')\n",
    "sns.pairplot(df[cols_features_+['target_']], hue='target_',palette='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from sklearn.feature_selection import chi2\n",
    "# fsel = SelectKBest(chi2, k=4).fit( df[cols_features], df['target'])\n",
    "# fsel.pvalues_\n",
    "# # X = SelectKBest(chi2, k=4).fit_transform( df[cols_features], df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.svm import SVR\n",
    "# support = RFE(SVR(kernel=\"linear\"), n_features_to_select=5, step=1).fit(df[cols_features].values, df['target'].values ).support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df[cols_features_].values\n",
    "X = df[cols_features].values\n",
    "y = df['target_'].values\n",
    "display( X.shape,y.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X2 = PCA(n_components=2).fit_transform(X)\n",
    "display( X2.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# X2 = TSNE(n_components=2).fit_transform(X)\n",
    "# display( X2.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "for c in sorted(set(y)): # for c in [3,4]: \n",
    "    ax.scatter(X2[y==c, 0], X2[y==c, 1],s=1,label=f'{c}')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# выделить тестовые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.10, random_state=42)\n",
    "display( X_train.shape, X_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(y_train) , set(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# загружаем и обучаем модель классификатора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn : Nearest Neighbors.    \n",
    "https://scikit-learn.org/stable/modules/neighbors.html     \n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = KNeighborsClassifier().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn : Model selection: choosing estimators and their parameters.    \n",
    "https://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = [\n",
    "#     'braycurtis',\n",
    "#     'canberra',\n",
    "#     'chebyshev',\n",
    "#     'cityblock',\n",
    "#     'correlation',\n",
    "#     'cosine',\n",
    "#     'dice',\n",
    "#     'euclidean',\n",
    "#     'hamming',\n",
    "#     'jaccard',\n",
    "#     #'jensenshannon',\n",
    "#     #'kulczynski1',\n",
    "#     # 'mahalanobis',\n",
    "#     'minkowski',\n",
    "#     'rogerstanimoto',\n",
    "#     'russellrao',\n",
    "#     #'seuclidean',\n",
    "#     'sokalmichener',\n",
    "#     'sokalsneath',\n",
    "#     'sqeuclidean',\n",
    "#     #'yule',\n",
    "# ]\n",
    "\n",
    "# param_grid= {\n",
    "#     'n_neighbors': range(1,10),\n",
    "#     'metric': metrics,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# # применяем методы поиска оптимальных гиперпараметров модели\n",
    "# grid = GridSearchCV(\n",
    "#         estimator=KNeighborsClassifier(),\n",
    "#         param_grid=param_grid,\n",
    "#     ).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display( grid.best_score_ )\n",
    "# display( grid.best_params_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# model = RandomForestClassifier( n_estimators=128, max_depth=8,).fit(X_train,y_train)\n",
    "model = RandomForestClassifier().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# model = GaussianNB().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ipytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%ipytest\n",
    "\n",
    "# def test_no_duplicates():\n",
    "#     assert df.duplicated().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# оценка результатов классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn : Metrics and scoring: quantifying the quality of predictions   \n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report # метрики качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "# y_pred = model_.predict(X_train)\n",
    "\n",
    "print(classification_report(\n",
    "    y_true=y_train,\n",
    "    y_pred=y_pred,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model_.predict(X_test)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix # количество ошибок\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "247.594px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
